import re
import logging
import streamlit as st

from data.db import init_db, kpi_revenue, kpi_orders, top_products
from llm.agent import chat, SYSTEM_PROMPT
from llm.client import get_openai_client

# ----------------- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ -----------------
st.set_page_config(page_title="Capstone Generative AI Agent", page_icon="ü§ñ", layout="wide")
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(name)s | %(message)s")
log = logging.getLogger("app")

# ----------------- –î–µ–∫–æ—Ä (CSS) -----------------
st.markdown(
    """
<style>
:root{
  --bg:#0f1117; --panel:#151a23; --card:#11151d; --muted:#a3a7b7;
  --text:#f1f5f9; --accent:#7c3aed; --accent2:#06b6d4; --good:#22c55e;
}
html, body, .stApp { background: var(--bg); color: var(--text); }
.block-container { padding-top: 1.2rem; padding-bottom: 2.2rem; }

h1.title {
  font-size: 2rem; font-weight: 800; letter-spacing: .2px;
  background: linear-gradient(90deg, var(--accent), var(--accent2));
  -webkit-background-clip: text; -webkit-text-fill-color: transparent;
  margin: .2rem 0 1rem 0;
}
.badge {
  display:inline-flex; align-items:center; gap:.5rem; padding:.35rem .6rem; border-radius:999px;
  background:#1b2130; border:1px solid #232c40; font-size:.85rem; color:var(--muted);
}
.badge .dot{ width:.55rem; height:.55rem; border-radius:50%; display:inline-block; }
.badge .on{ background: var(--good); box-shadow:0 0 10px var(--good); }
.badge .off{ background: #ef4444; box-shadow:0 0 10px #ef4444; }

.section { background: #121827; border: 1px solid #232c40; border-radius: 14px; padding: .8rem; }

.kpi-card {
  background: #11151d; border: 1px solid #21293a; border-radius: 14px; padding: .8rem 1rem; margin-bottom:.6rem;
}
.kpi-title { font-size:.82rem; color:var(--muted); margin:0 0 .15rem 0; }
.kpi-value { font-size:1.2rem; font-weight:700; }

.quickbar { display:flex; gap:.5rem; }
button[kind="secondary"] { border-radius:999px !important; }

.stChatMessage { margin-bottom:.65rem; }
.stChatMessage div[data-testid="stMarkdownContainer"] p { margin:.2rem 0; }
footer {visibility:hidden;}
</style>
""",
    unsafe_allow_html=True,
)

# ----------------- –î–æ–º–µ–Ω–Ω—ã–µ –≥–∞—Ä–¥—Ä–µ–π–ª—ã -----------------
REFUSAL_TEXT = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –º–æ–≥—É –æ—Ç–≤–µ—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∑–∞–∫–∞–∑–∞–º, KPI –∏ –ø–æ–≥–æ–¥–µ."
KWD_RE = re.compile(
    r"(–∑–∞–∫–∞–∑|–ø—Ä–æ–¥–∞–∂|–≤—ã—Ä—É—á–∫|^kpi$|kpi|–∫–µ–π–ø–∏–∞–π|–º–µ—Ç—Ä–∏–∫|–ø–æ–∫–∞–∑–∞—Ç–µ–ª"
    r"|–ø–æ–≥–æ–¥[–∞—É–µ—ã]|–¥–æ—Å—Ç–∞–≤–∫|–ª–æ–≥–∏—Å—Ç|—Ç–æ–ø|—Ç–æ–≤–∞—Ä)",
    re.IGNORECASE
)

def is_allowed_prompt(text: str) -> bool:
    return bool(KWD_RE.search(text or ""))

def guard_answer(text: str) -> str:
    return text if is_allowed_prompt(text or "") else REFUSAL_TEXT

# ----------------- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è -----------------
init_db()

if "history" not in st.session_state:
    st.session_state.history = [{"role": "system", "content": SYSTEM_PROMPT}]

# –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
if "queued_prompt" not in st.session_state:
    st.session_state.queued_prompt = ""

# ----------------- –í–µ—Ä—Ö–Ω—è—è –ø–∞–Ω–µ–ª—å -----------------
client, model = get_openai_client()
status_html = f"""
<div class="badge">
  <span class="dot {'on' if client else 'off'}"></span>
  <span>{'Online' if client else 'Offline'}</span>
  <span style="opacity:.7">¬∑</span>
  <span>model: <b>{model}</b></span>
</div>
"""
left, right = st.columns([0.8, 0.2])
with left:
    st.markdown('<h1 class="title">ü§ñ Capstone Generative AI Agent</h1>', unsafe_allow_html=True)
with right:
    st.markdown(status_html, unsafe_allow_html=True)

# ----------------- –ë—ã—Å—Ç—Ä—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ -----------------
with st.container():
    st.markdown('<div class="section">**–ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—Ä–æ—Å:**</div>', unsafe_allow_html=True)
    c1, c2, c3, c4, c5 = st.columns(5)
    def queue_and_rerun(text: str):
        st.session_state.queued_prompt = text
        st.rerun()

    if c1.button("–ü–æ–∫–∞–∂–∏ –≤—Å–µ –∑–∞–∫–∞–∑—ã", use_container_width=True):
        queue_and_rerun("–ü–æ–∫–∞–∂–∏ –≤—Å–µ –∑–∞–∫–∞–∑—ã")
    if c2.button("–î–∞–π –∑–∞–∫–∞–∑—ã –ò–≤–∞–Ω–∞", use_container_width=True):
        queue_and_rerun("–î–∞–π –∑–∞–∫–∞–∑—ã –ò–≤–∞–Ω–∞")
    if c3.button("–ü–æ–≥–æ–¥–∞ –¥–ª—è Moscow –Ω–∞ —Å–µ–≥–æ–¥–Ω—è", use_container_width=True):
        queue_and_rerun("–ü–æ–≥–æ–¥–∞ –¥–ª—è Moscow –Ω–∞ —Å–µ–≥–æ–¥–Ω—è")
    if c4.button("–¢–û–ü —Ç–æ–≤–∞—Ä—ã", use_container_width=True):
        queue_and_rerun("–¢–û–ü —Ç–æ–≤–∞—Ä—ã")
    if c5.button("–ö–∞–∫–æ–π KPI?", use_container_width=True):
        queue_and_rerun("–ö–∞–∫–æ–π KPI?")

# ----------------- –†–µ–Ω–¥–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏ (–±–µ–∑ –ø—É—Å—Ç—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π) -----------------
for m in st.session_state.history[1:]:
    content = (m.get("content") or "").strip()
    if not content:
        continue
    with st.chat_message(m["role"]):
        st.markdown(content)

# ----------------- –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è -----------------
typed = st.chat_input("–°–ø—Ä–æ—Å–∏—Ç–µ –ø—Ä–æ –∑–∞–∫–∞–∑—ã, KPI –∏–ª–∏ –ø–æ–≥–æ–¥—É –¥–ª—è –¥–æ—Å—Ç–∞–≤–∫–∏‚Ä¶")
prompt = typed or st.session_state.queued_prompt
# —Å—Ä–∞–∑—É –æ—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å, —á—Ç–æ–±—ã –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–ª–æ—Å—å
if st.session_state.queued_prompt:
    st.session_state.queued_prompt = ""

if prompt:
    st.session_state.history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    if not is_allowed_prompt(prompt):
        text = REFUSAL_TEXT
        st.session_state.history.append({"role": "assistant", "content": text})
        with st.chat_message("assistant"):
            st.markdown(text)
    else:
        result = chat(st.session_state.history)
        if result["type"] == "llm":
            m = result["message"]
            safe_text = (guard_answer(m.content or "")).strip()
            if safe_text:
                st.session_state.history.append({"role": "assistant", "content": safe_text})
                with st.chat_message("assistant"):
                    st.markdown(safe_text)
        else:
            text = (result.get("content", "")).strip()
            if text:
                st.session_state.history.append({"role": "assistant", "content": text})
                with st.chat_message("assistant"):
                    st.markdown(text)

# ----------------- –°–∞–π–¥–±–∞—Ä KPI -----------------
with st.sidebar:
    st.markdown("### üìä –ë–∏–∑–Ω–µ—Å-–ø–∞–Ω–µ–ª—å")
    st.markdown('<div class="kpi-card"><div class="kpi-title">–í—ã—Ä—É—á–∫–∞</div>'
                f'<div class="kpi-value">${kpi_revenue():,.2f}</div></div>', unsafe_allow_html=True)
    cA, cB = st.columns(2)
    with cA:
        st.markdown('<div class="kpi-card"><div class="kpi-title">–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤</div>'
                    f'<div class="kpi-value">{kpi_orders()}</div></div>', unsafe_allow_html=True)
    with cB:
        st.markdown('<div class="kpi-card"><div class="kpi-title">–¢–û–ü-—Ç–æ–≤–∞—Ä—ã</div>', unsafe_allow_html=True)
        for r in top_products(5):
            st.markdown(f"- {r['product']} ‚Äî ${r['revenue']}")
        st.markdown("</div>", unsafe_allow_html=True)

st.caption("–õ–æ–≥–∏ –ø–∏—à—É—Ç—Å—è –≤ stdout. –ö–ª—é—á–∏ –±–µ—Ä—É—Ç—Å—è –∏–∑ .env/ENV.")
