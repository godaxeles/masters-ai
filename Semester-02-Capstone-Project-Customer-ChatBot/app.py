from __future__ import annotations
import os, yaml
import streamlit as st
from typing import List
from rag.index import FaissIndex
from rag.retriever import HybridRetriever
from rag.prompt import build_prompt
from rag.llm import LLM, LLMConfig
from rag.ticketing import Ticketing, Ticket
from dotenv import load_dotenv, find_dotenv
IN_HF_SPACE = bool(os.environ.get("SPACE_ID", ""))   # –ø—Ä–∏–∑–Ω–∞–∫, —á—Ç–æ –∫–æ–¥ –∫—Ä—É—Ç–∏—Ç—Å—è –≤ Space
load_dotenv(find_dotenv(), override=not IN_HF_SPACE)


@st.cache_resource(show_spinner=False)
def load_config() -> dict:
    """–ï–¥–∏–Ω–æ—Ä–∞–∑–æ–≤–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç config.yaml."""
    with open("config.yaml", "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

@st.cache_resource(show_spinner=True)
def load_index() -> FaissIndex:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥–æ—Ç–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å. –ï—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –∏ –º—ã –≤ Hugging Face Space,
    –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–±–∏—Ä–∞–µ–º –∏–∑ ./data –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º.
    """
    idx = FaissIndex()
    try:
        idx.load()
        return idx
    except Exception as e:
        # –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —Å–æ–±–∏—Ä–∞–µ–º –≤ —Ä–∞–Ω—Ç–∞–π–º–µ
        IN_HF_SPACE = bool(os.environ.get("SPACE_ID", ""))
        if IN_HF_SPACE:
            from rag.loader import DocumentLoader
            st.info("–ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–±–∏—Ä–∞—é –∏–∑ ./data –ø—Ä—è–º–æ –≤ Space‚Ä¶")
            loader = DocumentLoader("data")
            idx.build_from_loader(loader, chunk_size=900, chunk_overlap=150)
            idx.save()
            st.success("–ò–Ω–¥–µ–∫—Å —Å–æ–±—Ä–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
            return idx
        # –ª–æ–∫–∞–ª—å–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±—Ä–æ—Å–∞—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ (–∫–∞–∫ –±—ã–ª–æ)
        raise



@st.cache_resource(show_spinner=False)
def init_llm(cfg: dict) -> LLM | None:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç LLM. –ï—Å–ª–∏ –∫–ª—é—á–µ–π –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None, –∞ UI –ø–æ–∫–∞–∂–µ—Ç –ø–æ–¥—Å–∫–∞–∑–∫—É."""
    provider = os.environ.get("LLM_PROVIDER")
    model = os.environ.get("LLM_MODEL")
    if not provider:
        provider = "openai" if os.environ.get("OPENAI_API_KEY") else cfg.get("provider_fallback", "hf")
    if not model:
        model = "gpt-4o-mini" if provider == "openai" else "meta-llama/Meta-Llama-3-8B-Instruct"
    try:
        llm_conf = LLMConfig(provider=provider, model=model,
                             temperature=cfg.get("temperature", 0.1),
                             max_tokens=cfg.get("max_tokens", 700))
        return LLM(llm_conf)
    except Exception as e:
        st.warning(f"LLM –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {e}. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è OpenAI –∏–ª–∏ HF (—Å–º. README).")
        return None

def user_asked_ticket(text: str) -> bool:
    t = (text or "").lower()
    triggers = ["—Å–æ–∑–¥–∞–π —Ç–∏–∫–µ—Ç", "—Å–æ–∑–¥–∞—Ç—å —Ç–∏–∫–µ—Ç", "—Ç–∏–∫–µ—Ç", "ticket", "issue", "jira", "trello", "github"]
    return any(k in t for k in triggers)

def answer_with_flag(llm, prompt, chunks):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (answer_text, not_found: bool).
    –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç –∏–ª–∏ –æ–Ω –ø—É—Å—Ç–æ–π ‚Äî not_found=True –∏ –æ—Ç–¥–∞—ë–º —á–µ—Å—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    """
    if not chunks:  # –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–æ—Å—å –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        return ("–Ø –Ω–µ –Ω–∞—à—ë–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö. "
                "–ú–æ–≥—É –æ—Ñ–æ—Ä–º–∏—Ç—å —Ç–∏–∫–µ—Ç, —á—Ç–æ–±—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –≤–µ—Ä–Ω—É–ª—Å—è —Å —Ç–æ—á–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º."), True
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å—Ç—å ‚Äî —Å–ø—Ä–∞—à–∏–≤–∞–µ–º LLM
    ans = llm.chat(prompt.system, prompt.user)
    return ans, False


# ------------------------- UI -------------------------
st.set_page_config(page_title="Contoso Motors ‚Äî Support RAG", page_icon="üõ†Ô∏è", layout="wide")
config = load_config()
company = config.get("company", {})
retrieval_cfg = config.get("retrieval", {})
llm_cfg = config.get("llm", {})
ui_cfg = config.get("ui", {})

st.title("üõ†Ô∏è Customer Support RAG ‚Äî —Ç–æ–ª—å–∫–æ –ø–æ –¥–∞–Ω–Ω—ã–º")
st.caption(f"–ö–æ–º–ø–∞–Ω–∏—è: {company.get('name')} | Email: {company.get('contact_email')} | –¢–µ–ª.: {company.get('contact_phone')}")

with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    st.write("LLM –∏ –∏–Ω–¥–µ–∫—Å")
    top_k = st.slider("Top‚ÄëK –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", min_value=2, max_value=12, value=int(retrieval_cfg.get("top_k", 6)))
    min_score = st.slider("–ü–æ—Ä–æ–≥ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è", 0.0, 1.0, float(retrieval_cfg.get("min_score", 0.3)), 0.01)
    max_ctx = st.slider("–ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", 2000, 20000, int(retrieval_cfg.get("max_context_chars", 12000)), 500)
    temperature = st.slider("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", 0.0, 1.0, float(llm_cfg.get("temperature", 0.1)), 0.05)
    if st.button("–ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å –∏–∑ data/", type="secondary"):
        st.info("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –ª–æ–∫–∞–ª—å–Ω–æ: `python scripts/build_index.py --rebuild` (–≤ Space –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ)")

# –ö—ç—à–∏—Ä—É–µ–º/–≥—Ä—É–∑–∏–º –∏–Ω–¥–µ–∫—Å –∏ LLM
index = load_index()
retriever = HybridRetriever(index, min_score=min_score)
llm = init_llm({"provider_fallback": llm_cfg.get("provider_fallback", "hf"),
                "temperature": temperature,
                "max_tokens": llm_cfg.get("max_tokens", 700)})

if "history" not in st.session_state:
    st.session_state.history = []  # [(user, assistant)]

# –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ—Ç LLM
if llm is None:
    st.warning("LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPENAI_API_KEY –∏–ª–∏ HF_API_TOKEN –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ LLM_PROVIDER/LLM_MODEL (—Å–º. README).")

# –í–≤–æ–¥ –ø–æ Enter
q = st.chat_input("–°–ø—Ä–æ—Å–∏—Ç–µ –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∫–æ–º–ø–∞–Ω–∏–∏‚Ä¶")  # Enter –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç
clear = st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é", type="secondary")

if clear:
    st.session_state.history = []
    st.experimental_rerun()

# –ò—Å—Ç–æ—Ä–∏—è
for i, (u, a) in enumerate(st.session_state.history[-8:]):
    st.chat_message("user").write(u)
    st.chat_message("assistant").write(a)

if q and llm is not None:
    with st.spinner("–ò—â—É –æ—Ç–≤–µ—Ç –ø–æ –≤–∞—à–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º‚Ä¶"):
        chunks = retriever.retrieve(q, top_k=top_k, max_context_chars=max_ctx)
        prompt = build_prompt(q, chunks, company)
        answer, not_found = answer_with_flag(llm, prompt, chunks)

    st.chat_message("user").write(q)
    st.chat_message("assistant").write(answer)

    # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞–π–¥–µ–Ω
    if not not_found and chunks:
        with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (–∫–æ–Ω—Ç–µ–∫—Å—Ç)"):
            for i, c in enumerate(chunks, 1):
                st.markdown(f"**#{i} ‚Äî {c.source}{(' p.' + str(c.page)) if c.page else ''} | score={c.score:.2f}**")
                st.write(c.text)
                st.divider()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–ª–∞–≥, —á—Ç–æ–±—ã —Ä–µ—à–∞—Ç—å ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ñ–æ—Ä–º—É —Ç–∏–∫–µ—Ç–∞ –∏–ª–∏ –Ω–µ—Ç
    st.session_state.history.append((q, answer))
    st.session_state.last_not_found = not_found

# –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏
if clear:
    st.session_state.history = []
    st.session_state.last_not_found = False
    st.experimental_rerun()


# –ë–ª–æ–∫ —Ç–∏–∫–µ—Ç–æ–≤
# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–æ—Ä–º—É —Ç–∏–∫–µ—Ç–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∞–º –ø–æ–ø—Ä–æ—Å–∏–ª
# –ò–õ–ò –µ—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç –±—ã–ª not_found
show_ticket_form = False
if "last_not_found" in st.session_state and st.session_state.last_not_found:
    show_ticket_form = True
if q and user_asked_ticket(q):
    show_ticket_form = True

if show_ticket_form:
    st.subheader("–°–æ–∑–¥–∞—Ç—å —Ç–∏–∫–µ—Ç")
    with st.form("ticket_form"):
        name = st.text_input("–í–∞—à–µ –∏–º—è")
        email = st.text_input("–í–∞—à email")
        title = st.text_input("–ó–∞–≥–æ–ª–æ–≤–æ–∫")
        desc = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã")
        submit = st.form_submit_button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å")
    if submit:
        if not (name and email and title and desc):
            st.error("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –≤—Å–µ –ø–æ–ª—è, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")
        else:
            tk = Ticketing()
            ident = tk.create(Ticket(name=name, email=email, title=title, description=desc))
            st.success(f"–°–æ–∑–¥–∞–Ω —Ç–∏–∫–µ—Ç: {ident}")
